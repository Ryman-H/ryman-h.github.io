
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Robopatient — Face-mediated Human–Robot Interaction | Lalitharatne et al.</title>

  <!-- main site CSS -->
  <link rel="stylesheet" href="/assets/css/site.css" />
  <style>
    /* local adjustments for project pages (kept small) */
    .project-page{ max-width:1100px; margin:0 auto; padding:40px 20px; }
    .project-hero{ width:100%; border-radius:8px; margin-bottom:20px; display:block; }
    .project-meta{ margin:4px 0 18px; color:var(--muted); font-size:14px; }
    .project-intro{ font-size:16px; line-height:1.6; margin-bottom:18px; max-width:900px; }
    .project-points{ list-style:none; padding:0; margin:0 0 20px; }
    .project-points li{ margin-bottom:10px; font-size:15px; line-height:1.55; }
    .project-pubs{ list-style:none; padding:0; margin:10px 0 8px; }
    .project-pubs li{ margin-bottom:8px; font-size:15px; }
    .project-pubs a{ color:var(--accent); text-decoration:none; }
    .project-pubs a:hover{ text-decoration:underline; }
    .project-back{ margin-top:28px; }
    .project-source { font-size:13px; color:var(--muted); margin-top:8px; }
  </style>
</head>

<body>

  <!-- placeholder for included header -->
  <div id="site-header"></div>

  <main class="project-page">

    <!-- Hero (image / video) -->
    <img class="project-hero" src="/assets/images/robopatient-hero.jpg" alt="Robopatient — MorphFace and setup photo" />

    <h1>Robopatient — Face-mediated Human–Robot Interaction</h1>
    <p class="project-meta">
      <em>Lalitharatne, T. D.; Costi, L.; Hashem, R.; Nisky, I.; Jack, R. E.; Nanayakkara, T.; Iida, F. — Scientific Reports (2022)</em>
    </p>

    <!-- Short overview -->
    <p class="project-intro">
      The Robopatient platform demonstrates a face-mediated human–robot interaction paradigm for remote palpation and medical examination.
      A tactile sensor array on a teleoperated “robodoctor” measures haptic response from an abdominal phantom; the high-dimensional tactile data are compressed
      and rendered as pain facial expressions on a hybrid physical/virtual robotic face (MorphFace) at the operator site. This low-dimensional, biologically familiar
      visual feedback recruits human expertise in decoding facial cues and yields more accurate localization of hard nodules in an in-vitro palpation task
      compared to a direct visual tactile map.
    </p>

    <!-- Key points -->
    <ul class="project-points">
      <li><strong>Problem:</strong> Remote palpation systems commonly present tactile data as color maps or haptic stimuli; these formats can be information-dense and unintuitive for quick clinical interpretation.</li>
      <li><strong>Approach:</strong> Robopatient maps a 60-taxel capacitive tactile array into four pain-related facial Action Units (AU4, AU7, AU9, AU10) synthesized on MorphFace, and teleoperates a UR5 robot to reproduce operator palpation at a remote site.</li>
      <li><strong>Validation:</strong> A user study (n=17) tasked participants to localize an embedded 15 mm hard nodule in a silicone phantom. Face-mediated feedback produced significantly lower localization error and higher accuracy (mean accuracy ~83.8% vs 67.4%) without increasing search time. (See experiment details and figures in the source paper.)</li>
      <li><strong>Domain:</strong> Telemedicine · human–robot interaction · tactile sensing · facial expression synthesis · medical device testing.</li>
    </ul>

    <!-- Related publications (Google Scholar keyword links) -->
    <h3>Related publications</h3>
    <ul class="project-pubs">
      <li>
        <a href="https://scholar.google.com/scholar?q=face+mediated+human-robot+interaction+palpation" target="_blank" rel="noopener">
          Face-mediated human–robot interaction (palpation)
        </a>
      </li>
      
    </ul>

    <p class="project-pubs-more">
      <a href="https://scholar.google.com/scholar?q=Lalitharatne+Hashem+Robopatient" target="_blank" rel="noopener">
        View related works on Google Scholar →
      </a>
    </p>



    <!-- Back link -->
    <p class="project-back">
      <a href="/#gallery">← Back to Projects</a>
    </p>

  </main>

  <!-- placeholder for included footer -->
  <div id="site-footer"></div>

  <!-- include header/footer and set active nav -->
  <script>
    // load includes
    fetch('/assets/includes/header.html')
      .then(r => r.text())
      .then(html => {
        document.getElementById('site-header').innerHTML = html;
        // after header inserted, mark Projects link active
        try {
          const navLinks = document.querySelectorAll('.main-nav a[data-nav]');
          navLinks.forEach(a => a.classList.remove('active'));
          const projectsLink = document.querySelector('.main-nav a[data-nav="projects"]');
          if (projectsLink) projectsLink.classList.add('active');
        } catch (e) { /* ignore */ }
      });

    fetch('/assets/includes/footer.html')
      .then(r => r.text())
      .then(html => { document.getElementById('site-footer').innerHTML = html; });
  </script>

  <!-- small style for active nav (if you don't already have it in site.css) -->
  <style>
    .main-nav a.active { font-weight:600; text-decoration:underline; }
  </style>

</body>
</html>
